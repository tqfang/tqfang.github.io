---
permalink: /
title: "Tianqing Fang"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm a researcher at Tencent AI Lab. 
I got my Ph.D. degree from HKUST in the summer of 2024, supervised by [Prof. Yangqiu Song](https://cse.hkust.edu.hk/~yqsong/). 
Previously, I was a visiting Ph.D. student at EPFL, working with Prof. [Antoine Bosselut](https://atcbosselut.github.io/), a visiting research scholar at University of Southern California, working with Prof. [Muhao Chen](https://muhaochen.github.io/). I received my B.E. degree from Zhejiang University in 2019, where I was supervised by [Prof. Yang Yang](http://yangy.org/) and was a member Advanced Class of Engineering Education (ACEE) in Chu Ko Chen Honors College.
Here is my [Curriculum Vitae (April 2024)](https://tqfang.github.io/files/tianqing_CV.pdf).


Research Interest
------


Current Topic:

- VLM/LLM-based Agent. 
- Self-improvement and evolvement of Agent. 


Topic in Ph.D.:

- **Knowledge Acquisition:** Commonsense knowledge acquisition at scale using information extraction ([ASER](https://hkust-knowcomp.github.io/ASER/html/index.html)) and knowledge base population ([DISCOS](https://arxiv.org/abs/2101.00154), [CKBP](https://arxiv.org/abs/2109.07679), [PseudoReasoner](https://arxiv.org/abs/2210.07988)); Conceptualization knowledge acquisition ([AbstractATOMIC](https://arxiv.org/abs/2206.01532), [CAT](https://arxiv.org/abs/2305.04808)).
- **Reasoning with knowledge for (Large) Language Models:** Integration of (abstract) commonsense knowledge to language models ([CAR](http://arxiv.org/abs/2305.14869)); Complex reasoning over knowledge graphs ([COM2](https://arxiv.org/abs/2403.07398)); Knowledge constrained decoding for LLMs ([KCTS](https://arxiv.org/abs/2310.09044)); Knowledge conflicts detection and mitigation ([CDA](https://arxiv.org/abs/2305.14970)); Dialogue system with knowledge.
- **Machine Learning for NLP:** Data denoising ([ODDA](https://arxiv.org/abs/2212.10558)), training dynamics ([QAD](https://arxiv.org/abs/2310.11303)), ...

News
------
- 5/2025: üÜï New paper: [WebCoT](https://arxiv.org/abs/2505.20013), crafting reasoning chain-of-thought for web agent. 
- 5/2025: üêÜ [Leopard](https://arxiv.org/abs/2410.01744), multimodal language model and data focusing on text-rich, multiimage scenarios, has been accepted by TMLR!
- 5/2025: üöÄ 3 papers accepted to ACL and ACL Findings! Checkout [OpenWebVoyager](https://arxiv.org/abs/2410.19609), [Parallel Context Encoding](https://arxiv.org/pdf/2412.16545), and [ConceptEdit](https://arxiv.org/pdf/2412.11418)!
- 5/2025: üöÄ Invited as Senior Area Chair of AACL 2025!
- 4/2025: üÜï Released two technical reports about Web Agent. [WebEvolver](https://tqfang.github.io/files/agent_world_model.pdf), self-improving Agent with World Model, and [Web Agent Rollback](https://arxiv.org/abs/2504.11788).
- 4/2025: üéì Awarded as a Finalist for the School of Engineering (SENG) PhD Research Excellence Award 2024‚Äì25. Many thanks to my supervisor and all collaborators for their support!
- 1/2025: üöÄ The [Concept-reversed Winograd Schema Challenge](https://arxiv.org/abs/2410.12040) paper was accepted to NAACL 2025 main conference. Congratulations to Kaiqiao and the team!
- 8/2024: üéì Successfully defended my Ph.D.!
- 5/2024: üöÄ 3 papers accepted to ACL main conference! 
- 5/2024: üöÄ Our original paper of [conceptualization](https://arxiv.org/abs/2206.01532) is finally accepted by Artifitial Intelligence journal after two years (many of the follow-up works are already accepted by conferences though). Big shout out to Mutian, who has put tremendous efforts into this amazing work.
<!-- - 4/2024: Invited to serve as Senior Area Chair of ACL ARR in April 2024! -->
<!-- - 3/2024: 2 papers accepted to Findings of NAACL 2024! -->
<!-- - 2/2024: Invited to serve as Area Chair of ACL 2024. -->
<!-- - 1/2024: 3 papers accepted to EACL 2024 and 1 paper accepted to ICLR 2024! -->
<!-- - 1/2024: Invited to serve as PC for NAACL 2024 and IJCAI 2024. -->
<!-- - 10/2023: Invited to serve as the PC for COLING-LREC 2024, and the reviewer for EACL 2023 (ARR). -->
<!-- - 10/2023: 5 papers accepted to EMNLP. Topics includes zero-shot commonsense QA (2 findings), knowledge-constrained decoding (main), a benchmark for analogy reasoning (main), a benchmark for academic writing formalization (main). -->
<!-- - 9/2023: Invited to serve as the PC for SDM 2024. -->
<!-- - 6/2023: Invited to serve as the PC for AAAI 2024. -->
<!-- - 5/2023: Two paper accepted to ACL 2023 main conference. -->
<!-- - 4/2023: Preprints about [ChatGPT on discourse relations](https://arxiv.org/abs/2304.14827) and an updated benchmark of [CSKB Population](https://arxiv.org/abs/2304.10392) are released. -->

Publication
------

### Preprint


<!-- - **Tianqing Fang\***, Quyet V. Do\*, Sehyun Choi, Weiqi Wang, Yangqiu Song.        
**CKBP v2: An Expert-Annotated Evaluation Set for Commonsense Knowledge Base Population**, 2023
[\[paper\]](https://arxiv.org/abs/2304.10392) [\[code&data\]](https://github.com/HKUST-KnowComp/CSKB-Population/)    -->    

- **Tianqing Fang**, Hongming Zhang, Zhisong Zhang, Kaixin Ma, Wenhao Yu, Haitao Mi, Dong Yu.         
**WebEvolver: Enhancing Web Agent Self-Improvement with Co-evolving World Model**       
[\[paper\]](https://arxiv.org/abs/2504.21024) [\[code\]](TBA)

- Minda Hu\*, **Tianqing Fang\***, Jianshu Zhang, Junyu Ma, Zhisong Zhang, Jingyan Zhou, Hongming Zhang, Haitao Mi, Dong Yu, Irwin King      
**WebCoT: Enhancing Web Agent Reasoning by Reconstructing Chain-of-Thought in Reflection, Branching, and Rollback**       
[\[paper\]](https://arxiv.org/abs/2505.20013) [\[code\]](TBA)

- Zhisong Zhang, **Tianqing Fang**, Kaixin Ma, Wenhao Yu, Hongming Zhang, Haitao Mi, Dong Yu.         
**Enhancing Web Agents with Explicit Rollback Mechanisms**       
[\[paper\]](https://arxiv.org/abs/2504.11788) [\[code\]](TBA)

- Zhaowei Wang, Hongming Zhang, **Tianqing Fang**, Ye Tian, Yue Yang, Kaixin Ma, Xiaoman Pan, Yangqiu Song, Dong Yu.         
**DivScene: Benchmarking LVLMs for Object Navigation with Diverse Scenes and Objects**       
[\[paper\]](https://arxiv.org/abs/2410.02730) [\[code\]](https://github.com/zhaowei-wang-nlp/DivScene)         




### Journal

2025

- Mengzhao Jia, Wenhao Yu, Kaixin Ma, **Tianqing Fang**, Zhihan Zhang, Siru Ouyang, Hongming Zhang, Meng Jiang, Dong Yu.         
**LEOPARD: A Vision Language Model For Text-Rich Multi-Image Tasks**       
*TMLR* [\[paper\]](https://arxiv.org/abs/2410.01744) [\[code\]](https://github.com/tencent-ailab/Leopard)

2024

- Mutian He, **Tianqing Fang**, Weiqi Wang, and Yangqiu Song.      
**Acquiring and Modelling Abstract Commonsense Knowledge via Conceptualization,**         
*Artificial Intelligence,* 2024. [\[paper\]](https://arxiv.org/abs/2206.01532) [\[code\]](https://github.com/HKUST-KnowComp/atomic-conceptualization)

2022

- Hongming Zhang\*, Xin Liu\*, Haojie Pan\*, Haowen Ke, Jiefu Ou, **Tianqing Fang**, and Yangqiu Song.       
**ASER: Towards Large-scale Commonsense Knowledge Acquisition via Higher-order Selectional Preference over Eventualities.**        
*Artificial Intelligence,* 2022. [\[paper\]](https://www.sciencedirect.com/science/article/pii/S0004370222000807) [\[arxiv\]](https://arxiv.org/abs/2104.02137) [\[code\]](https://github.com/HKUST-KnowComp/ASER) [\[homepage\]](https://hkust-knowcomp.github.io/ASER)


### Conference

2025

- Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, **Tianqing Fang**, Zhenzhong Lan and Dong Yu         
**OpenWebVoyager: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization**          
ACL 2025, [\[paper\]](https://arxiv.org/abs/2410.19609) [\[code\]](https://github.com/MinorJerry/OpenWebVoyager)

- Zhisong Zhang, Yan Wang, Xinting Huang, **Tianqing Fang**, Hongming Zhang, Chenlong Deng, Shuaiyi Li, Dong Yu      
**Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models**         
ACL 2025, [\[paper\]](https://arxiv.org/pdf/2412.11418)

- Liyu Zhang, Weiqi Wang, **Tianqing Fang**, Yangqiu Song       
**ConceptEdit: Conceptualization-Augmented Knowledge Editing in Large Language Models for Commonsense Reasoning**        
Findings of ACL 2025, [\[paper\]](https://arxiv.org/pdf/2412.11418)


- Kaiqiao Han\*, **Tianqing Fang** \*, Zhaowei Wang, Yangqiu Song, Mark Steedman.         
**Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction**       
*NAACL 2025*. [\[paper\]](https://arxiv.org/abs/2410.12040) [\[code&data\]](https://github.com/HKUST-KnowComp/Adv-WSC)


2024

- **Tianqing Fang**, Zeming Chen, Yangqiu Song, Antoine Bosselut.        
**Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs**       
*ACL 2024*. [\[paper\]](https://arxiv.org/abs/2403.07398)[\[code\]](https://github.com/tqfang/COM2-complex-commonsense-reasoning/)

- Weiqi Wang, **Tianqing Fang**, Chunyang Li, Haochen Shi, Wenxuan Ding, Baixuan Xu, Zhaowei Wang, Jiaxin Bai, Xin Liu, Jiayang Cheng, Chunkit Chan, Yangqiu Song.       
**CANDLE: Iterative Conceptualization and Instantiation Distillation from Large Language Models for Commonsense Reasoning.**, 2024       
*ACL 2024*.  [\[paper\]](https://arxiv.org/abs/2401.07286) [\[code&data\]](https://github.com/HKUST-KnowComp/CANDLE)  

- Zhaowei Wang, Wei Fan, Qing Zong, Hongming Zhang, Sehyun Choi, **Tianqing Fang**, Xin Liu, Yangqiu Song, Ginny Y. Wong, Simon See.        
**AbsInstruct: Eliciting Abstraction Ability from LLMs through Explanation Tuning with Plausibility Estimation**     
*ACL 2024*. [\[paper\]](https://arxiv.org/abs/2402.10646) [\[code&data\]](https://github.com/HKUST-KnowComp/AbsInstruct)  

- **Tianqing Fang**, Zhaowei Wang, Wenxuan Zhou, Hongming Zhang, Yangqiu Song, Muhao Chen.       
**Getting Sick After Seeing a Doctor? Diagnosing and Mitigating Knowledge Conflicts in Event Temporal Reasoning**,      
*Findings of NAACL 2024* [\[paper\]](https://arxiv.org/abs/2305.14970)

- Zhaowei Wang, Haochen Shi, Weiqi Wang, **Tianqing Fang**, Hongming Zhang, Sehyun Choi, Xin Liu, Yangqiu Song       
**AbsPyramid: Benchmarking the Abstraction Ability of Language Models with a Unified Entailment Graph**        
*Findings of NAACL 2024* [\[paper\]](https://arxiv.org/abs/2311.09174)

- **Tianqing Fang**, Wenxuan Zhou, Fangyu Liu, Hongming Zhang, Yangqiu Song, and Muhao Chen.     
**On-the-fly Denoising for Data Augmentation in Natural Language Understanding,**      
*Findings of EACL 2024* [\[paper\]](https://arxiv.org/abs/2212.10558)

- Chunkit Chan, Jiayang Cheng, Weiqi Wang, Yuxin Jiang, **Tianqing Fang**, Xin Liu, Yangqiu Song.        
**ChatGPT Evaluation on Sentence Level Relations: A Focus on Temporal, Causal, and Discourse Relations**,       
*Findings of EACL 2024* [\[paper\]](https://arxiv.org/abs/2304.14827)

- Quyet V. Do, **Tianqing Fang**, Shizhe Diao, Zhaowei Wang, Yangqiu Song.        
**ConstraintChecker: A Plugin for Large Language Models to Reason on Commonsense Knowledge Bases**      
*EACL 2024* [\[paper\]](https://arxiv.org/abs/2401.14003)

- Xiongye Xiao, Gengshuo Liu, Gaurav Gupta, Defu Cao, Shixuan Li, Yaxing Li, **Tianqing Fang**, Mingxi Cheng, Paul Bogdan.       
**Neuro-Inspired Hierarchical Multimodal Learning**,          
*ICLR 2024* [\[paper\]](https://openreview.net/forum?id=Z9AZsU1Tju)


- Baixuan Xu\*, Weiqi Wang\*, Haochen Shi, Wenxuan Ding, Huihao Jing, **Tianqing Fang**, Jiaxin Bai, Xin Liu, Changlong Yu, Zheng Li, Chen Luo, Qingyu Yin, Bing Yin, Long Chen, Yangqiu Song.          
**MIND: Multimodal Shopping Intention Distillation from Large Vision-language Models for E-commerce Purchase Understanding.**       
EMNLP 2024 [\[paper\]](https://arxiv.org/pdf/2406.10701) [\[code\]](https://github.com/HKUST-KnowComp/MIND_Distillation)    



- Wenxuan Ding\*, Weiqi Wang\*, Sze Heng Douglas Kwok, Minghao Liu, **Tianqing Fang**, Jiaxin Bai, Xin Liu, Changlong Yu, Zheng Li, Chen Luo, Qingyu Yin, Bing Yin, Junxian He, Yangqiu Song.         
**IntentionQA: A Benchmark for Evaluating Purchase Intention Comprehension Abilities of Language Models in E-commerce.**        
*Findings of EMNLP 2024* [\[paper\]](https://arxiv.org/pdf/2406.10173) [\[code\]](https://github.com/HKUST-KnowComp/IntentionQA)           


 



2023

- Sehyun Choi, **Tianqing Fang**, Zhaowei Wang, Yangqiu Song   
**KCTS: Knowledge-Constrained Tree Search Decoding with Token-Level Hallucination Detection**     
*Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023 (Main Conference),* [\[paper\]](https://arxiv.org/abs/2310.09044) [\[code\]](https://github.com/HKUST-KnowComp/Knowledge-Constrained-Decoding)

- Jiayang Cheng, Lin Qiu, Tsz Ho CHAN, **Tianqing Fang**, Weiqi Wang, Chunkit Chan, Qipeng Guo, Hongming Zhang, Yangqiu Song, Yue Zhang, Zheng Zhang     
**STORYANALOGY: Deriving Story-level Analogies from Large Language Models to Unlock Analogical Understanding**    
*Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023 (Main Conference),* [\[paper\]](https://arxiv.org/abs/2310.12874) [\[code&data\]](https://github.com/loginaway/StoryAnalogy)

- Shizhe Diao, Yongyu Lei, Liangming Pan, **Tianqing Fang**, Wangchunshu Zhou, Sedrick Scott Keh, Min-Yen Kan, Tong Zhang    
**Doolittle: Benchmarks and Corpora for Academic Writing Formalization**     
*Conference on Empirical Methods in Natural Language Processing (EMNLP), 2023 (Main Conference),* [\[paper\]](https://openreview.net/attachment?id=B3rTZovgaA&name=pdf) [\[code&data\]](https://github.com/shizhediao/Doolittle)  

- Weiqi Wang\*, **Tianqing Fang\***, Wenxuan Ding, Baixuan Xu, Xin Liu, Yangqiu Song, Antoine Bosselut.   
**CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering**, 2023     
*Findings of Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP)*, 2023. [\[paper\]](http://arxiv.org/abs/2305.14869) [\[code\]](https://github.com/HKUST-KnowComp/CAR)

- Haochen SHI, Weiqi Wang, **Tianqing Fang**, Baixuan Xu, Wenxuan Ding, Xin Liu, Yangqiu Song     
**QADYNAMICS: Training Dynamics-Driven Synthetic QA Diagnostic for Zero-Shot Commonsense Question Answering**      
*Findings of Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP)*, 2023. [\[paper\]](https://arxiv.org/abs/2310.11303) [\[code\]](https://github.com/HKUST-KnowComp/QaDynamics)


- Weiqi Wang\*, **Tianqing Fang\***, Baixuan Xu, Chun Yi Louis Bo, Yangqiu Song, Lei Chen.        
**üêàCAT: A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning**        
*Annual Meeting of the Association for Computational Linguistics (ACL),* 2023. [\[pdf\]](https://arxiv.org/abs/2305.04808) [\[code\]](https://github.com/HKUST-KnowComp/CAT).

- Zhaowei Wang, Quyet V. Do, Hongming Zhang, Jiayao Zhang, Weiqi Wang, **Tianqing Fang**, Yangqiu Song, Ginny Y. Wong, Simon See        
**COLA: Contextualized Commonsense Causality Reasoning from the Causal Inference Perspective**        
*Annual Meeting of the Association for Computational Linguistics (ACL),* 2023. [\[pdf\]](https://arxiv.org/abs/2305.05191) [\[code\]](https://github.com/HKUST-KnowComp/COLA).


2022

- **Tianqing Fang**, Quyet V. Do, Hongming Zhang, Yangqiu Song, Ginny Y. Wong and Simon See.        
**PseudoReasoner: Leveraging Pseudo Labels for Commonsense Knowledge Base Population.**      
*Findings of Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP)*, 2022. [\[pdf\]](https://arxiv.org/abs/2210.07988) [\[code\]](https://github.com/HKUST-KnowComp/PseudoReasoner).    
*Internship work at NVIDIA*

-  Ying Su, Zihao Wang, **Tianqing Fang**, Hongming Zhang, Yangqiu Song and Tong Zhang.       
**MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation.**       
*Findings of Conference on Empirical Methods in Natural Language Processing (Findings of EMNLP),* 2022. [\[pdf\]](https://arxiv.org/abs/2210.07570) [\[code\]](https://github.com/HKUST-KnowComp/MICO).

- Zhaowei Wang, Hongming Zhang, **Tianqing Fang**, Yangqiu Song, Ginny Y. Wong and Simon See.          
**SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller.**          
*Conference on Empirical Methods in Natural Language Processing (EMNLP),* 2022. [\[pdf\]](https://arxiv.org/abs/2210.06694) [\[code\]](https://github.com/HKUST-KnowComp/SubeventWriter).

- Ziqian Zeng, Weimin Ni, **Tianqing Fang**, Xiang Li, Xinran Zhao, and Yangqiu Song.         
**Weakly Supervised Text Classification using Supervision Signals from a Language Model.**         
*Findings of Annual Conference of the North American Chapter of the Association for Computational Linguistics (Findings of NAACL),* 2022. [\[pdf\]](https://arxiv.org/pdf/2205.06604.pdf) [\[code\]](https://github.com/HKUST-KnowComp/WDDC).

2021

- **Tianqing Fang\***, Weiqi Wang\*, Sehyun Choi, Shibo Hao, Hongming Zhang, Yangqiu Song, Bin He.        
**Benchmarking Commonsense Knowledge Base Population with an Effective Evaluation Dataset.**        
*Conference on Empirical Methods in Natural Language Processing (EMNLP), 2021 (Main Conference),* [\[pdf\]](https://arxiv.org/abs/2109.07679) [\[v2\]](https://arxiv.org/abs/2304.10392) [\[code\]](https://github.com/HKUST-KnowComp/CSKB-Population) [\[video\]](https://www.youtube.com/watch?v=5pLLHaPrx-I)


- **Tianqing Fang**, Haojie Pan, Hongming Zhang, Yangqiu Song, Kun Xu, Dong Yu.          
**Do Boat and Ocean Suggest Beach? Dialogue Summarization with External Knowledge.**          
*Conference on Automated Knowledge Base Construction (AKBC),* 2021. [\[pdf\]](https://www.akbc.ws/2021/papers/AJKd0iIFMDc) [\[code\]](https://github.com/HKUST-KnowComp/CODC-Dialogue-Summarization)
- Nedjma Ousidhoum, Xinran Zhao, **Tianqing Fang**, Yangqiu Song, and Dit-Yan Yeung.          
**Probing Toxic Content in Large Pre-Trained Language Models.**          
*Annual Meeting of the Association for Computational Linguistics (ACL),* 2021. [\[pdf\]](https://github.com/HKUST-KnowComp/Probing_toxicity_in_PTLMs/blob/main/probing_toxic_content_acl2021.pdf) [\[code\]](https://github.com/HKUST-KnowComp/Probing_toxicity_in_PTLMs)
- **Tianqing Fang**, Hongming Zhang, Weiqi Wang, Yangqiu Song, and Bin He.          
**DISCOS: Bridging the Gap between Discourse Knowledge and Commonsense Knowledge.**          
*The Web Conference (WWW),* 2021. [\[pdf\]](https://arxiv.org/abs/2101.00154) [\[code\]](https://github.com/HKUST-KnowComp/DISCOS-commonsense) [\[video\]](https://www.youtube.com/watch?v=Ogzyf8gj5IM&t=1s)


\*: Equal Contribution

**Ph.D. thesis:**

**Commonsense Knowledge Base Population and Reasoning for Inferential Knowledge**. [\[pdf\]](https://tqfang.github.io/files/Tianqing_Ph_D__thesis.pdf)



Awards
------
- Finalist of School of Engineering (SENG) PhD Research Excellence Award 2024-25 (a top honor in SENG HKUST) (2025)
- HKUST RedBird Academic Excellence Award for Continuing PhD Students in 2023/24 (2024)
- HKUST Overseas Research Award (2023)
- HKUST RedBird Academic Excellence Award for Continuing PhD Students in 2022/23 (2023)
- HKUST RedBird Academic Excellence Award for Continuing PhD Students in 2021/22 (2022)
- Hong Kong Ph.D. Fellowship (2019-2023)
- Special Scholarship for Undergraduate Students in Zhejiang University (one of the top honor in ZJU) (2018)
- Provincial Scholarship (top 5%, ZJU, 2018)
- 1st Place and MATLAB Innovation Award (1st/36K+) in [Contemporary Undergraduate Mathematical Contest in Modeling](http://en.mcm.edu.cn/) (2017)
- Provincial Scholarship (top 5%, ZJU, 2017)
- National Scholarship (top 3%, ZJU, 2016)

Teaching
------
- MSBD 5018: Natural Language Processing (Spring 2022)
- COMP5222/MATH5471: Statistical Learning Models for Text and Graph Data. (Fall 2021)
- MSBD6000H: Natural Language Processing. (Spring 2021)
- COMP4901K/MATH4824B: Machine Learning for Natural Language Processing. (Fall 2020)
- COMP4332/RMBI4310: Big Data Mining. (Spring 2020)

Academic Service
------
- Conference Area Chair: ARR (Feb/April, 24) -> ACL 2024, EMNLP 2024
- Conference Reviewer: ACL Rolling Review, AAAI'23-24, ACL'23, COLING'22-24, EMNLP'22-23, IJCAI'23-24, KDD'23-24
- Conference External Reviewer: KDD'20, 21, ACL'21, EMNLP'21

Miscs:
-----
Check out some of my photography works on [unsplash](https://unsplash.com/@tqfang). 

Also, my cat Mili is a KOC (key opinion cat) on [Rednote/Xiaohongshu](https://www.xiaohongshu.com/user/profile/614af023000000000201e2d9).

<a href="https://clustrmaps.com/site/1am85"  title="Visit tracker" style="width: 250px"><img src="//www.clustrmaps.com/map_v2.png?d=1rGYEOu6BaCxnSv3lwCWOBjlq9pFF_8iT_upuStA-JY&cl=ffffff" /></a>

<!-- 

A data-driven personal website
======
Like many other Jekyll-based GitHub Pages templates, academicpages makes you separate the website's content from its form. The content & metadata of your website are in structured markdown files, while various other files constitute the theme, specifying how to transform that content & metadata into HTML pages. You keep these various markdown (.md), YAML (.yml), HTML, and CSS files in a public GitHub repository. Each time you commit and push an update to the repository, the [GitHub pages](https://pages.github.com/) service creates static HTML pages based on these files, which are hosted on GitHub's servers free of charge.

Many of the features of dynamic content management systems (like Wordpress) can be achieved in this fashion, using a fraction of the computational resources and with far less vulnerability to hacking and DDoSing. You can also modify the theme to your heart's content without touching the content of your site. If you get to a point where you've broken something in Jekyll/HTML/CSS beyond repair, your markdown files describing your talks, publications, etc. are safe. You can rollback the changes or even delete the repository and start over -- just be sure to save the markdown files! Finally, you can also write scripts that process the structured data on the site, such as [this one](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb) that analyzes metadata in pages about talks to display [a map of every location you've given a talk](https://academicpages.github.io/talkmap.html).

Getting started
======
1. Register a GitHub account if you don't have one and confirm your e-mail (required!)
1. Fork [this repository](https://github.com/academicpages/academicpages.github.io) by clicking the "fork" button in the top right. 
1. Go to the repository's settings (rightmost item in the tabs that start with "Code", should be below "Unwatch"). Rename the repository "[your GitHub username].github.io", which will also be your website's URL.
1. Set site-wide configuration and create content & metadata (see below -- also see [this set of diffs](http://archive.is/3TPas) showing what files were changed to set up [an example site](https://getorg-testacct.github.io) for a user with the username "getorg-testacct")
1. Upload any files (like PDFs, .zip files, etc.) to the files/ directory. They will appear at https://[your GitHub username].github.io/files/example.pdf.  
1. Check status by going to the repository settings, in the "GitHub pages" section

Site-wide configuration
------
The main configuration file for the site is in the base directory in [_config.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_config.yml), which defines the content in the sidebars and other site-wide features. You will need to replace the default variables with ones about yourself and your site's github repository. The configuration file for the top menu is in [_data/navigation.yml](https://github.com/academicpages/academicpages.github.io/blob/master/_data/navigation.yml). For example, if you don't have a portfolio or blog posts, you can remove those items from that navigation.yml file to remove them from the header. 

Create content & metadata
------
For site content, there is one markdown file for each type of content, which are stored in directories like _publications, _talks, _posts, _teaching, or _pages. For example, each talk is a markdown file in the [_talks directory](https://github.com/academicpages/academicpages.github.io/tree/master/_talks). At the top of each markdown file is structured data in YAML about the talk, which the theme will parse to do lots of cool stuff. The same structured data about a talk is used to generate the list of talks on the [Talks page](https://academicpages.github.io/talks), each [individual page](https://academicpages.github.io/talks/2012-03-01-talk-1) for specific talks, the talks section for the [CV page](https://academicpages.github.io/cv), and the [map of places you've given a talk](https://academicpages.github.io/talkmap.html) (if you run this [python file](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.py) or [Jupyter notebook](https://github.com/academicpages/academicpages.github.io/blob/master/talkmap.ipynb), which creates the HTML for the map based on the contents of the _talks directory).

**Markdown generator**

I have also created [a set of Jupyter notebooks](https://github.com/academicpages/academicpages.github.io/tree/master/markdown_generator
) that converts a CSV containing structured data about talks or presentations into individual markdown files that will be properly formatted for the academicpages template. The sample CSVs in that directory are the ones I used to create my own personal website at stuartgeiger.com. My usual workflow is that I keep a spreadsheet of my publications and talks, then run the code in these notebooks to generate the markdown files, then commit and push them to the GitHub repository.

How to edit your site's GitHub repository
------
Many people use a git client to create files on their local computer and then push them to GitHub's servers. If you are not familiar with git, you can directly edit these configuration and markdown files directly in the github.com interface. Navigate to a file (like [this one](https://github.com/academicpages/academicpages.github.io/blob/master/_talks/2012-03-01-talk-1.md) and click the pencil icon in the top right of the content preview (to the right of the "Raw | Blame | History" buttons). You can delete a file by clicking the trashcan icon to the right of the pencil icon. You can also create new files or upload files by navigating to a directory and clicking the "Create new file" or "Upload files" buttons. 

Example: editing a markdown file for a talk
![Editing a markdown file for a talk](/images/editing-talk.png)

For more info
------
More info about configuring academicpages can be found in [the guide](https://academicpages.github.io/markdown/). The [guides for the Minimal Mistakes theme](https://mmistakes.github.io/minimal-mistakes/docs/configuration/) (which this theme was forked from) might also be helpful.
 -->
